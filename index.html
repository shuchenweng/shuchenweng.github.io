<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Shuchen Weng - BAAI</title>
  
  <meta name="author" content="Shuchen Weng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">

  <style>
    /* === Ê†∏ÂøÉÂ∏ÉÂ±Ä === */
    body {
      background-color: #f0f2f5; 
      color: #333;
      font-family: 'Roboto', sans-serif;
      font-size: 17px; 
      line-height: 1.6;
      margin: 0;
      padding: 40px 0;
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      background-color: #ffffff;
      padding: 50px 60px;
      box-shadow: 0 4px 25px rgba(0,0,0,0.05);
      border-radius: 8px;
    }

    a { color: #0066cc; text-decoration: none; transition: all 0.2s ease; }
    a:hover { color: #cc0000; }
    
    h1, h2, h3 { font-family: 'Lato', sans-serif; color: #111; }
    h1 { font-size: 2.4em; font-weight: 700; margin-bottom: 20px; letter-spacing: -0.5px; }
    
    h2 { 
      font-size: 1.5em; 
      margin-top: 60px;
      margin-bottom: 25px;
      padding-bottom: 10px;
      border-bottom: 2px solid #f0f2f5;
      position: relative;
    }
    h2::after {
        content: '';
        display: block; width: 60px; height: 4px; background: #0066cc;
        position: absolute; bottom: -3px; left: 0;
    }

    /* ÂàÜÁ±ªÂ∞èÊ†áÈ¢ò */
    h3 {
        font-size: 1.2em;
        margin-top: 40px;
        margin-bottom: 20px;
        color: #555;
        border-left: 4px solid #ddd;
        padding-left: 10px;
    }
    
    /* === ÂàóË°®Ê†∑Âºè === */
    ul.text-list { padding-left: 20px; margin-top: 0; }
    ul.text-list li { margin-bottom: 15px; }

    /* === È°∂ÈÉ®‰∏™‰∫∫‰ø°ÊÅØ === */
    .header-container { display: flex; align-items: flex-start; gap: 50px; }
    .profile-info { flex: 1; } 
    
    .bio-list p { margin: 5px 0; font-size: 1.1em; }
    .email-line { margin-top: 10px; font-family: 'Roboto', sans-serif; font-weight: 700; color: #333; }

    .profile-img-container { flex-shrink: 0; }
    .profile-img { 
      width: 200px; height: 200px; object-fit: cover; border-radius: 50%; box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }

    .social-links { margin-top: 25px; }
    .social-links a {
      display: inline-block; margin-right: 12px; font-size: 0.95em; color: #444;
      background: #f7f9fa; padding: 5px 10px; border-radius: 5px; border: 1px solid #e1e4e8;
    }
    .social-links a:hover { background: #fff; border-color: #ccc; color: #000; }

    /* === ËÆ∫ÊñáÂàóË°® === */
    .paper-item { 
      margin-bottom: 30px;
    }
    
    .paper-title { font-size: 1.15em; font-weight: 700; color: #000; margin-bottom: 6px; display: block; line-height: 1.3; }
    .paper-author { color: #555; margin-bottom: 6px; font-size: 1em; display: block; }
    .paper-venue { color: #cc0000; font-weight: bold; font-style: italic; font-size: 0.9em; }
    .paper-links { margin-top: 8px; font-size: 0.85em; }
    .paper-links a { margin-right: 12px; font-weight: 600; text-transform: uppercase; }

    .tag-new {
        background-color: #ffebeb; color: #d32f2f; font-size: 0.7em; padding: 2px 6px;
        border-radius: 4px; margin-left: 6px; vertical-align: middle; font-weight: 800; text-transform: uppercase;
    }

    /* === ÈÄöËÆØ‰ΩúËÄÖ‰ø°Â∞ÅÂõæÊ†á (Á∫ØÂ±ïÁ§∫) === */
    .icon-mail {
      width: 14px; height: 14px; margin-left: 3px; vertical-align: middle;
      fill: #555; /* Ê∑±ÁÅ∞Ëâ≤ */
      margin-bottom: 2px;
    }

    /* ÁßªÂä®Á´ØÈÄÇÈÖç */
    @media (max-width: 768px) {
      .container { padding: 30px 20px; }
      .header-container { flex-direction: column-reverse; text-align: center; align-items: center; gap: 20px; }
      .profile-info { text-align: left; width: 100%; } 
      .profile-img { width: 160px; height: 160px; }
    }
  </style>
</head>

<body>

  <div class="container">
  
    <div class="header-container">
      <div class="profile-info">
        <h1>Shuchen Weng (ÁøÅ‰π¶Êô®)</h1>
        
        <div class="bio-list">
            <p><b>Technical Staff</b></p>
            <p><b>Beijing Academy of Artificial Intelligence (BAAI)</b></p>
            <p class="email-line">Email: shuchenweng [at] pku.edu.cn</p>
        </div>
        
        <div class="social-links">
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=-5qVEQsAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>
          <a href="https://ci.idm.pku.edu.cn/">Partner Lab</a>
        </div>
      </div>
      
      <div class="profile-img-container">
        <img src="photo.jpg" alt="Shuchen Weng" class="profile-img">
      </div>
    </div>

    <h2>üî• News</h2>
    <ul class="text-list">
      <li><b>[2025.12]</b> 1 paper accepted by <b>TPAMI</b>!</li>
      <li><b>[2025.09]</b> 1 paper accepted by <b>IJCV</b>!</li>
      <li><b>[2025.06]</b> 2 papers accepted by <b>NeurIPS 2025</b>!</li>
    </ul>

    <h2>Education</h2>
    <ul class="text-list">
        <li>
            <b>PhD at Peking University, Beijing, China</b><br>
            Advisors: Prof. Boxin Shi<br>
            Sep. 2019 ~ Jun. 2024, in NELVT, Dept. of Computer Science
        </li>
        <li>
            <b>Bachelor of Engineering at Tianjin University, Tianjin, China</b><br>
            Sep. 2015 ~ Jul. 2019, in College of Intelligence and Computing
        </li>
    </ul>

    <h2>Professional Experiences</h2>
    <ul class="text-list">
        <li>Jul. 2024 ~ Present, <b>technical staff at Beijing Academy of Artificial Intelligence (BAAI)</b>.</li>
        <li>Jan. 2023 ~ Jun. 2024, <b>research intern at Beijing Academy of Artificial Intelligence (BAAI)</b>.</li>
        <li>Feb. 2019 ~ Aug. 2019, <b>research intern at Peng Cheng Lab</b>.</li>
        <li>Aug. 2018 ~ Nov. 2018, <b>research intern at Tencent AI Lab</b>.</li>
    </ul>

    
    <h2>üìù Publications</h2>
    <p style="font-weight: bold; color: #444; margin-bottom: 30px;">
        TPAMI x 3, IJCV x 1, CVPR x 6, ECCV x 5, ICCV x 1, NeurIPS x 4, AAAI x 2
        <br>
        <span style="font-weight: normal; font-size: 0.9em; color: #666;">
            (<sup>‚Ä†</sup> equal contribution, 
            <svg class="icon-mail" viewBox="0 0 24 24" style="margin-left:0;"><path d="M20,4H4C2.895,4,2,4.895,2,6v12c0,1.105,0.895,2,2,2h16c1.105,0,2-0.895,2-2V6C22,4.895,21.105,4,20,4z M20,8.236l-8,4.882 L4,8.236V6h16V8.236z"></path></svg> corresponding author)
        </span>
    </p>

    <h3>Video Generation/Editing</h3>

    <div class="paper-item">
        <span class="paper-title">Audio-sync Video Instance Editing with Granularity-Aware Mask Refiner</span>
        <span class="paper-author">Haojie Zheng<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Jingqi Liu, Siqi Yang, Boxin Shi, Xinlong Wang</span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2512.10571?">[PDF]</a></div>
    </div>
    
    <div class="paper-item">
        <span class="paper-title">STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative</span>
        <span class="paper-author">
            Peixuan Zhang<sup>‚Ä†</sup>, Zijian Jia<sup>‚Ä†</sup>, Kaiqi Liu, 
            <b>Shuchen Weng</b><svg class="icon-mail" viewBox="0 0 24 24"><path d="M20,4H4C2.895,4,2,4.895,2,6v12c0,1.105,0.895,2,2,2h16c1.105,0,2-0.895,2-2V6C22,4.895,21.105,4,20,4z M20,8.236l-8,4.882 L4,8.236V6h16V8.236z"></path></svg>, 
            Si Li, Boxin Shi
        </span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2512.12372?">[PDF]</a></div>
    </div>
    
    <div class="paper-item">
        <span class="paper-title">Audio-Sync Video Generation with Multi-Stream Temporal Control <span class="tag-new">NEW</span></span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Haojie Zheng<sup>‚Ä†</sup>, Zheng Chang, Si Li, Boxin Shi, Xinlong Wang</span>
        <span class="paper-venue">NeurIPS 2025</span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2506.08003?">[PDF]</a></div>
        <a href="https://hjzheng.net/projects/MTV/">[Code]</a>

    </div>

    <div class="paper-item">
        <span class="paper-title">PanoWan: Lifting Diffusion Video Generation Models to 360 with Latitude/Longitude-aware Mechanisms <span class="tag-new">NEW</span></span>
        <span class="paper-author">Yifei Xia<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Siqi Yang, Jingqi Liu, Chengxuan Zhu, Minggui Teng, Zijian Jia, Han Jiang, Boxin Shi</span>
        <span class="paper-venue">NeurIPS 2025</span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2505.22016">[PDF]</a></div>
        <a href="https://github.com/VariantConst/PanoWan">[Code]</a>
    </div>

    <div class="paper-item">
        <span class="paper-title">VIRES: Video Instance Repainting with Sketch and Text Guidance</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Haojie Zheng<sup>‚Ä†</sup>, Peixuan Zhan, Yuchen Hong, Han Jiang, Si Li, Boxin Shi</span>
        <span class="paper-venue">CVPR 2025</span>
        <div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Weng_VIRES_Video_Instance_Repainting_via_Sketch_and_Text_Guided_Generation_CVPR_2025_paper.pdf">[PDF]</a></div>
        <a href="https://github.com/suimuc/VIRES/">[Code]</a>
    </div>

    <div class="paper-item">
        <span class="paper-title">L-C4: Language-Based Video Colorization for Creative and Consistent Color</span>
        <span class="paper-author">Zheng Chang, <b>Shuchen Weng</b>, Huan Ouyang, Yu Li, Si Li, Boxin Shi</span>
        <span class="paper-venue">Neurocomputing 2025</span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2410.04972">[PDF]</a></div>
    </div>

    <h3>Image Semantic Editing</h3>

    <div class="paper-item">
        <span class="paper-title">Towards Deeper Emotional Reflection: Crafting Affective Image Filters with Generative Priors<span class="tag-new">NEW</span></span>
        <span class="paper-author">Peixuan Zhang<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Jiajun Tang, Si Li, Boxin Shi</span>
        <span class="paper-venue">TPAMI 2025</span>
        <div class="paper-links"><span>[Coming Soon]</span></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Affective Image Editing: Shaping Emotional Factors via Text Descriptions<span class="tag-new">NEW</span></span>
        <span class="paper-author">Peixuan Zhang<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Chengxuan Zhu, Binghao Tang, Zijian Jia, Si Li, Boxin Shi</span>
        <span class="paper-venue">IJCV 2025</span>
        <div class="paper-links"><a href="https://arxiv.org/pdf/2505.18699?">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">PhyS-EdiT: Physics-aware Semantic Image Editing with Text Description</span>
        <span class="paper-author">Ziqi Cai, <b>Shuchen Weng</b>, Yifei Xia, Boxin Shi</span>
        <span class="paper-venue">CVPR 2025</span>
        <div class="paper-links"><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_PhyS-EdiT_Physics-aware_Semantic_Image_Editing_with_Text_Description_CVPR_2025_paper.pdf">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Affective Image Filter: Reflecting Emotions from Text to Images</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Peixuan Zhang<sup>‚Ä†</sup>, Zheng Chang, Xinlong Wang, Si Li, Boxin Shi</span>
        <span class="paper-venue">ICCV 2023</span>
        <div class="paper-links">
            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf">[PDF]</a>
            <a href="https://github.com/zpx0922/AIFormer">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Instance Contour Adjustment via Structure-driven CNN</span>
        <span class="paper-author"><b>Shuchen Weng</b>, Yi Wei, Ming-Ching Chang, Boxin Shi</span>
        <span class="paper-venue">ECCV 2022</span>
        <div class="paper-links"><a href="https://ci.idm.pku.edu.cn/Weng_ECCV22c.pdf">[PDF]</a></div>
    </div>

    <h3>Low-level Vision</h3>

    <div class="paper-item">
        <span class="paper-title">L-DiffER: Single image reflection removal with language-based diffusion model</span>
        <span class="paper-author">Yuchen Hong<sup>‚Ä†</sup>, Haofeng Zhong<sup>‚Ä†</sup>, <b>Shuchen Weng</b>, Jinxiu Liang, Boxin Shi</span>
        <span class="paper-venue">ECCV 2024</span>
        <div class="paper-links"><a href="https://assets.ctfassets.net/yreyglvi5sud/4uhN2PF7UyMGgiWQgCMSgi/41f4f9f46fbfa370b3ccd8fbcadbc2b3/2024______Hong_ECCV.pdf">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Language-guided Image Reflection Separation</span>
        <span class="paper-author">Haofeng Zhong<sup>‚Ä†</sup>, Yuchen Hong<sup>‚Ä†</sup>, <b>Shuchen Weng</b>, Jinxiu Liang, Boxin Shi</span>
        <span class="paper-venue">CVPR 2024</span>
        <div class="paper-links"><a href="https://assets.ctfassets.net/yreyglvi5sud/1ptZmtvx71hLcIKH5mrxWQ/c571786893f745aa5b2f2298e55cd869/Zhong_CVPR24.pdf">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">L-CAD: Language-based Colorization with Any-level Descriptions</span>
        <span class="paper-author">Zheng Chang<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Peixuan Zhang, Yu Li, Si Li, Boxin Shi</span>
        <span class="paper-venue">NeurIPS 2023 (Spotlight)</span>
        <div class="paper-links">
            <a href="https://arxiv.org/pdf/2305.15217.pdf">[PDF]</a>
            <a href="https://github.com/changzheng123/L-CAD">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">L-CoIns: Language-based Colorization with Instance Awareness</span>
        <span class="paper-author">Zheng Chang<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Peixuan Zhang, Yu Li, Si Li, Boxin Shi</span>
        <span class="paper-venue">CVPR 2023</span>
        <div class="paper-links">
            <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chang_L-CoIns_Language-Based_Colorization_With_Instance_Awareness_CVPR_2023_paper.pdf">[PDF]</a>
            <a href="https://github.com/changzheng123/L-CoIns">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">CT<sup>2</sup>: Colorization Transformer via Color Tokens</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Jimeng Sun<sup>‚Ä†</sup>, Yu Li, Si Li, Boxin Shi</span>
        <span class="paper-venue">ECCV 2022 (Oral)</span>
        <div class="paper-links">
            <a href="https://ci.idm.pku.edu.cn/Weng_ECCV22b.pdf">[PDF]</a>
            <a href="https://github.com/shuchenweng/CT2">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">L-CoDer: Language-based Colorization with Color-object Decoupling Transformer</span>
        <span class="paper-author">Zheng Chang<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Yu Li, Si Li, Boxin Shi</span>
        <span class="paper-venue">ECCV 2022</span>
        <div class="paper-links">
            <a href="https://ci.idm.pku.edu.cn/Weng_ECCV22g.pdf">[PDF]</a>
            <a href="https://github.com/changzheng123/L-CoDer">[Code]</a>
        </div>
    </div>
    
    <div class="paper-item">
        <span class="paper-title">L-CoDe: Language-based Colorization using Color-object Decoupled Conditions</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Hao Wu<sup>‚Ä†</sup>, Zheng Chang, Jiajun Tang, Si Li, Boxin Shi</span>
        <span class="paper-venue">AAAI 2022</span>
        <div class="paper-links">
            <a href="https://ci.idm.pku.edu.cn/Weng_AAAI22.pdf">[PDF]</a>
            <a href="https://github.com/changzheng123/L-CoDe">[Code]</a>
        </div>
    </div>


    <h3>Image Repainting</h3>

    <div class="paper-item">
        <span class="paper-title">OpenCIR: Conditional Image Repainting with Open Condition Mixture</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Xiaocheng Gong<sup>‚Ä†</sup>, Haojie Zheng<sup>‚Ä†</sup>, Xinlong Wang, Si Li, Boxin Shi</span>
        <span class="paper-venue">TPAMI 2025</span>
        <div class="paper-links"><a href="https://ieeexplore.ieee.org/document/11122618">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Conditional Image Repainting</span>
        <span class="paper-author"><b>Shuchen Weng</b>, Boxin Shi</span>
        <span class="paper-venue">TPAMI 2023</span>
        <div class="paper-links"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10313073">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">LuminAIRe: Illumination-Aware Conditional Image Repainting for Lighting-Realistic Generation</span>
        <span class="paper-author">Jiajun Tang, Haofeng Zhong, <b>Shuchen Weng</b>, Boxin Shi</span>
        <span class="paper-venue">NeurIPS 2023</span>
        <div class="paper-links"><a href="https://ci.idm.pku.edu.cn/Tang_NeurIPS23.pdf">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">UniCoRN: A Unified Conditional Image Repainting Network</span>
        <span class="paper-author">Jimeng Sun<sup>‚Ä†</sup>, <b>Shuchen Weng</b><sup>‚Ä†</sup>, Zheng Chang, Si Li, Boxin Shi</span>
        <span class="paper-venue">CVPR 2022</span>
        <div class="paper-links">
            <a href="https://ci.idm.pku.edu.cn/Weng_CVPR22c.pdf">[PDF]</a>
            <a href="https://github.com/shuchenweng/UniCoRN">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Conditional Image Repainting via Semantic Bridging and Piecewise Value Function</span>
        <span class="paper-author"><b>Shuchen Weng</b>, Wenbo Li, Dawei Li, Hongxia Jin, Boxin Shi</span>
        <span class="paper-venue">ECCV 2020</span>
        <div class="paper-links">
            <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540443.pdf">[PDF]</a>
            <a href="https://github.com/shuchenweng/TGC">[Code]</a>
        </div>
    </div>

    <div class="paper-item">
        <span class="paper-title">MISC: Multi-condition Injection and Spatially-adaptive Compositing for Conditional Person Image Synthesis</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Wenbo Li<sup>‚Ä†</sup>, Dawei Li, Hongxia Jin, Boxin Shi</span>
        <span class="paper-venue">CVPR 2020</span>
        <div class="paper-links">
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Weng_MISC_Multi-Condition_Injection_and_Spatially-Adaptive_Compositing_for_Conditional_Person_Image_CVPR_2020_paper.pdf">[PDF]</a>
            <a href="https://github.com/shuchenweng/MISC">[Code]</a>
        </div>
    </div>

    <h3>Others</h3>

    <div class="paper-item">
        <span class="paper-title">Colorizing Monochromatic Radiance Fields</span>
        <span class="paper-author">Yean Cheng, Renjie Wan, <b>Shuchen Weng</b>, Chengxuan Zhu, Yakun Chang, Boxin Shi</span>
        <span class="paper-venue">AAAI 2024 (Oral)</span>
        <div class="paper-links"><a href="https://ci.idm.pku.edu.cn/Cheng_AAAI24.pdf">[PDF]</a></div>
    </div>

    <div class="paper-item">
        <span class="paper-title">Dual-stream CNN for Structured Time Series Classification</span>
        <span class="paper-author"><b>Shuchen Weng</b><sup>‚Ä†</sup>, Wenbo Li<sup>‚Ä†</sup>, Yi Zhang, Siwei Lyu</span>
        <span class="paper-venue">ICASSP 2019</span>
        <div class="paper-links"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8682410">[PDF]</a></div>
    </div>

    <h2>üèÜ Awards</h2>
    <ul class="text-list">
      <li>Huawei TopMinds Program (Âçé‰∏∫Â§©ÊâçÂ∞ëÂπ¥), 2024</li>
      <li>Alibaba Taotian Group T-star Program (ÈòøÈáåÊ∑òÂ§©T-Star), 2024</li>
      <li>National Scholarship for Graduate Student, Peking University (Top 2%), 2023</li>
      <li>Academic Innovation Award (Exceptional Award), Peking University (Top 1%), 2022</li>
      <li>Outstanding Undergraduate Student Award, by China Computer Federation (CCF‰ºòÁßÄÂ§ßÂ≠¶ÁîüÂ•ñ), 2019</li>
      <li>National Scholarship for Bachelor Student of Tianjin University (Top 2%), 2017</li>
    </ul>

    <div style="margin-top: 60px; color: #bbb; font-size: 0.8em; text-align: center;">
      <p>Last updated: Jan. 2026</p>
    </div>

  </div>

</body>
</html>
