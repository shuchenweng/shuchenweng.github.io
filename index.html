<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Shuchen Weng - BAAI</title>
  
  <meta name="author" content="Shuchen Weng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">

  <style>
    /* æ ¸å¿ƒé‡ç½® */
    body {
      background-color: #ffffff;
      color: #222;
      font-family: 'Roboto', sans-serif; /* å­¦æœ¯ç•Œæ ‡å‡†æ— è¡¬çº¿å­—ä½“ */
      font-size: 16px;
      line-height: 1.6;
      margin: 0 auto;
      padding: 40px 20px;
      max-width: 1000px; /* ã€å…³é”®ã€‘åŠ å®½åˆ° 1000px */
    }

    /* é“¾æ¥é¢œè‰² - ç»å…¸çš„å­¦æœ¯è“ */
    a { color: #0066cc; text-decoration: none; transition: color 0.2s; }
    a:hover { color: #cc0000; text-decoration: underline; }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3 { font-family: 'Lato', sans-serif; color: #111; }
    h1 { font-size: 2.4em; font-weight: 700; margin-bottom: 10px; letter-spacing: -0.5px; }
    h2 { 
      font-size: 1.5em; 
      border-bottom: 2px solid #f2f2f2; 
      padding-bottom: 10px; 
      margin-top: 50px; 
      margin-bottom: 20px;
    }
    
    /* é¡¶éƒ¨ä¸ªäººä¿¡æ¯å¡ç‰‡ */
    .header-container {
      display: flex;
      align-items: flex-start; /* é¡¶éƒ¨å¯¹é½ */
      gap: 40px;
      margin-bottom: 50px;
    }
    .profile-info { flex: 7; } /* å·¦ä¾§æ–‡å­—å  70% */
    .profile-img-container { flex: 3; text-align: center; } /* å³ä¾§å›¾ç‰‡å  30% */
    
    .profile-img { 
      width: 240px; 
      height: 240px;
      object-fit: cover;
      border-radius: 50%; /* åœ†å½¢å¤´åƒï¼Œæƒ³è¦æ–¹å½¢å°±æ”¹æˆ 8px */
      box-shadow: 0 4px 12px rgba(0,0,0,0.15); /* å¢åŠ ä¸€ç‚¹é˜´å½±ç«‹ä½“æ„Ÿ */
    }

    .bio-text { font-size: 1.1em; color: #444; margin-bottom: 20px; }
    .email-text { font-family: 'Courier New', monospace; background: #f4f4f4; padding: 2px 6px; border-radius: 4px; }

    /* ç¤¾äº¤é“¾æ¥æŒ‰é’® */
    .social-links { margin-top: 15px; }
    .social-links a {
      display: inline-block;
      margin-right: 15px;
      font-weight: 500;
    }

    /* æ–°é—»åˆ—è¡¨ */
    .news-list { list-style: none; padding-left: 0; }
    .news-list li { margin-bottom: 10px; display: flex; }
    .news-date { font-weight: bold; min-width: 100px; color: #555; }

    /* è®ºæ–‡åˆ—è¡¨ä¼˜åŒ– */
    .paper-item { 
      margin-bottom: 25px; 
      display: flex; 
      flex-direction: column;
    }
    .paper-title { font-size: 1.1em; font-weight: 700; color: #000; display: block; }
    .paper-author { color: #555; margin: 4px 0; }
    .paper-venue { color: #cc0000; font-weight: bold; font-style: italic; }
    
    .tag-new {
        background-color: #ffdddd;
        color: #cc0000;
        font-size: 0.8em;
        padding: 1px 5px;
        border-radius: 3px;
        margin-left: 8px;
        vertical-align: middle;
        font-weight: bold;
    }

    /* ç§»åŠ¨ç«¯é€‚é… */
    @media (max-width: 768px) {
      .header-container { flex-direction: column-reverse; align-items: center; text-align: center; }
      .profile-img { width: 180px; height: 180px; margin-bottom: 20px; }
      .news-list li { flex-direction: column; }
      .profile-info { width: 100%; }
    }
  </style>
</head>

<body>

  <div class="header-container">
    <div class="profile-info">
      <h1>Shuchen Weng (ç¿ä¹¦ç›)</h1>
      <p class="bio-text">
        Technical Staff at <b>Beijing Academy of Artificial Intelligence (BAAI)</b>.
      </p>
      <p>
        I received my Ph.D. degree from Peking University in 2024, advised by Prof. <a href="#">Boxin Shi</a>. 
        Prior to that, I obtained my B.E. degree from Tianjin University. My research interests include 
        <b>Controllable Video Generation</b>, <b>Audio-Visual Learning</b>, and <b>Computer Vision</b>.
      </p>
      <p>
        Email: <span class="email-text">shuchenweng [at] pku.edu.cn</span>
      </p>
      
      <div class="social-links">
        <a href="YOUR_GOOGLE_SCHOLAR_LINK">[Google Scholar]</a>
        <a href="YOUR_GITHUB_LINK">[GitHub]</a>
        <a href="YOUR_TWITTER_LINK">[Twitter]</a>
      </div>
    </div>
    
    <div class="profile-img-container">
      <img src="photo.jpg" alt="Shuchen Weng" class="profile-img">
    </div>
  </div>

  <h2>ğŸ”¥ News</h2>
  <ul class="news-list">
    <li><span class="news-date">[2025.06]</span> <span>Three papers accepted by <b>NeurIPS 2025</b>!</span></li>
    <li><span class="news-date">[2025.02]</span> <span>One paper (VIRES) accepted by <b>CVPR 2025</b>.</span></li>
    <li><span class="news-date">[2024.07]</span> <span>Joined BAAI as a Technical Staff.</span></li>
  </ul>

  <h2>ğŸ“ Selected Publications</h2>
  <p style="color: #666; margin-bottom: 20px;">
    (Full list available on Google Scholar. * indicates equal contribution.)
  </p>

  <div class="paper-item">
    <span class="paper-title">Audio-Sync Video Generation with Multi-Stream Temporal Control <span class="tag-new">NeurIPS 2025</span></span>
    <span class="paper-author"><b>Shuchen Weng</b>*, Haojie Zheng*, Zheng Chang, Si Li, Boxin Shi, Xinlong Wang</span>
    <div>
      <span class="paper-venue">NeurIPS 2025</span> &nbsp;/&nbsp;
      <a href="https://arxiv.org/pdf/2506.08003?">Paper</a>
    </div>
  </div>

  <div class="paper-item">
    <span class="paper-title">PanoWan: Lifting Diffusion Video Generation Models to 360 with Latitude/Longitude-aware Mechanisms <span class="tag-new">NeurIPS 2025</span></span>
    <span class="paper-author">Yifei Xia*, <b>Shuchen Weng</b>*, Siqi Yang, Jingqi Liu, Chengxuan Zhu, Minggui Teng, Zijian Jia, Han Jiang, Boxin Shi</span>
    <div>
      <span class="paper-venue">NeurIPS 2025</span> &nbsp;/&nbsp;
      <a href="https://arxiv.org/pdf/2505.22016">Paper</a>
    </div>
  </div>

  <div class="paper-item">
    <span class="paper-title">VIRES: Video Instance Repainting with Sketch and Text Guidance</span>
    <span class="paper-author"><b>Shuchen Weng</b>*, Haojie Zheng*, Peixuan Zhan, Yuchen Hong, Han Jiang, Si Li, Boxin Shi</span>
    <div>
      <span class="paper-venue">CVPR 2025</span> &nbsp;/&nbsp;
      <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Weng_VIRES_Video_Instance_Repainting_via_Sketch_and_Text_Guided_Generation_CVPR_2025_paper.pdf">Paper</a>
    </div>
  </div>
  
  <div class="paper-item">
    <span class="paper-title">L-C4: Language-Based Video Colorization for Creative and Consistent Color</span>
    <span class="paper-author">Zheng Chang, <b>Shuchen Weng</b>, Huan Ouyang, Yu Li, Si Li, Boxin Shi</span>
    <div>
      <span class="paper-venue">Neurocomputing 2025</span> &nbsp;/&nbsp;
      <a href="https://arxiv.org/pdf/2410.04972">Paper</a>
    </div>
  </div>

  <div class="paper-item">
    <span class="paper-title">Affective Image Filter: Reflecting Emotions from Text to Images</span>
    <span class="paper-author"><b>Shuchen Weng</b>*, Peixuan Zhang*, Zheng Chang, Xinlong Wang, Si Li, Boxin Shi</span>
    <div>
      <span class="paper-venue">ICCV 2023</span> &nbsp;/&nbsp;
      <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf">Paper</a> &nbsp;/&nbsp; 
      <a href="https://github.com/zpx0922/AIFormer">Code</a>
    </div>
  </div>

  <div class="paper-item">
    <span class="paper-title">CT<sup>2</sup>: Colorization Transformer via Color Tokens</span>
    <span class="paper-author"><b>Shuchen Weng</b>*, Jimeng Sun*, Yu Li, Si Li, Boxin Shi</span>
    <div>
      <span class="paper-venue">ECCV 2022 (Oral)</span> &nbsp;/&nbsp;
      <a href="https://ci.idm.pku.edu.cn/Weng_ECCV22b.pdf">Paper</a> &nbsp;/&nbsp; 
      <a href="https://github.com/shuchenweng/CT2">Code</a>
    </div>
  </div>


  <h2>ğŸ’¼ Experience</h2>
  <ul>
    <li><b>Beijing Academy of Artificial Intelligence (BAAI)</b> | Technical Staff | <i>Jul. 2024 - Present</i></li>
    <li><b>Beijing Academy of Artificial Intelligence (BAAI)</b> | Research Intern | <i>Jan. 2023 - Jun. 2024</i></li>
    <li><b>Peng Cheng Lab</b> | Research Intern | <i>Feb. 2019 - Aug. 2019</i></li>
    <li><b>Tencent AI Lab</b> | Research Intern | <i>Aug. 2018 - Nov. 2018</i></li>
  </ul>

  <h2>ğŸ† Selected Awards</h2>
  <ul>
    <li>Huawei TopMinds Program (åä¸ºå¤©æ‰å°‘å¹´), 2024</li>
    <li>Alibaba Taotian Group T-star Program (é˜¿é‡Œæ·˜å¤©T-Star), 2024</li>
    <li>National Scholarship for Graduate Student, Peking University (Top 2%), 2023</li>
    <li>Academic Innovation Award (Exceptional Award), Peking University (Top 1%), 2022</li>
  </ul>

  <div style="margin-top: 50px; color: #888; font-size: 0.9em;">
    <p>Last updated: Jan. 2026</p>
  </div>

</body>
</html>
